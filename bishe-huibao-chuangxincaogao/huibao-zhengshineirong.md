# 开题报告汇报发言稿

## 课题名称：基于大模型语义融合的时间序列预测模型设计与实现

---

## 第一页：封面

各位老师好，今天我汇报的题目是"基于大模型语义融合的时间序列预测模型设计与实现"。下面我将从研究背景、项目理解、技术路线、当前工作、创新设计和后续计划等方面进行汇报。

---

## 第二页：汇报目录

本次汇报主要包括以下九个部分：研究背景、项目理解、项目优势与可训练参数、国内外研究现状、研究方法与技术路线、当前完成工作、五项创新点设计、后续计划，以及研究成果价值展望。



---
## 第三页：研究背景

首先介绍研究背景。时间序列预测是数据科学领域的核心任务，广泛应用于能源负荷预测、金融市场分析、交通流量预测、气象预报等关键场景。准确的时序预测能够为决策者提供科学依据，降低运营成本，具有重要的社会经济价值。

然而，传统统计模型如ARIMA在面对复杂非线性模式和长程依赖时表现不足。虽然深度学习方法在一定程度上缓解了这些问题，但从零训练的模型缺乏预训练知识，泛化能力和可解释性仍有明显不足。这正是本课题研究的出发点。

---
---
## 第四页：国内外研究现状

国内外研究现状可分为四类：

第一类是基于Transformer的时序模型，代表工作包括PatchTST、iTransformer、TimesNet，它们在长序列建模上取得了显著进展，但缺乏预训练知识。

第二类是多尺度与混合模型，如TimeMixer、N-BEATS、ES-RNN，能够捕获多尺度模式，但计算开销较大。

第三类是LLM用于时序预测，如Time-LLM、AutoTimes、Time-MoE，利用了预训练知识，但可解释性不足。

第四类是可解释性增强方法，如Temporal Fusion Transformer，实现了预测过程的透明化。

现有研究尚缺乏系统性地将传统模型优势与LLM重编程范式深度融合的工作，这正是本课题的切入点。

## 第五页：项目理解

本课题以Time-LLM为基础框架。Time-LLM的核心思想是跨模态知识迁移，通过"重编程"技术将时序数据映射到大语言模型的语义空间。

具体来说，它包含两个核心机制：第一是输入重编程，通过Patching分块和Projection投影，将时间序列映射到LLM的词向量空间，使LLM将时序特征视为特殊的文本特征；第二是提示重编程，将数据的统计特征如均值、方差、趋势等转化为自然语言提示，激活LLM内部的模式识别能力。

这种设计的精妙之处在于：LLM权重完全冻结，仅训练轻量级的适配层，既利用了预训练知识，又避免了大规模参数更新带来的计算开销。

---

## 第六页：项目优势 - 可训练参数

这张表展示了Time-LLM的可训练参数分布。PatchEmbedding约800个参数，负责将Patch嵌入到特征空间；Mapping Layer约5000万参数，是最大的参数块，负责词表压缩映射；Reprogramming Layer约600万参数，实现跨模态对齐；FlattenHead约3.7万参数，负责输出投影。

总计约5600万可训练参数，而LLM骨干网络完全冻结。这种"冻结主干加轻量微调"的设计非常高效，使得在资源受限的环境下也能利用大模型的能力。

---



## 第七页：研究方法与技术路线

本课题的总体技术路线是：冻结LLM骨干网络，加上轻量可训练模块，再加上结构化创新模块。

在硬件适配方面，由于本机显存仅有6GB，无法直接运行原论文使用的LLAMA-7B模型。本课题采用Qwen 2.5 3B模型，通过4-bit量化将显存占用压缩至约1.5GB，成功实现了论文复现。

在创新实现方面，计划依次实现残差学习混合架构、变量间注意力增强、频域增强等模块，并通过可配置开关集成到统一框架，便于进行消融实验和对比分析。

---

## 第八页：当前完成工作

目前已完成以下工作：

第一，环境搭建。配置了WSL加4-bit量化加混合精度训练的实验环境。

第二，论文复现。在复现过程中解决了数据类型不匹配、显存溢出等多个技术问题，包括transformers版本兼容、4-bit量化的dtype统一、llm_layers参数调优等。

第三，验证运行。在ETTh1数据集上运行1个epoch，验证了项目可以正确复现，训练Loss从1.29稳步下降至0.2到0.3区间，模型正常收敛。

第四，创新方案设计。完成了五个主要创新点的理论分析和设计文档。

---

## 第九页：创新点概述

本课题设计了五项创新点。创新点一是可解释性增强与传统模型集成，灵感来源于ES-RNN和N-BEATS；创新点二是分段自适应融合，参考了AMD Framework的设计思想；创新点三是变量间注意力增强，灵感来源于iTransformer；创新点四是频域FFT增强，借鉴了TimesNet的频域分解思想；创新点五是动态Prompt生成，参考了AutoTimes的自适应机制。

下面逐一介绍这五项创新点。

---

## 第十页：创新点一 - 可解释性增强与传统模型集成

创新点一针对的问题是：Time-LLM的预测过程仍是黑盒，缺乏可解释性。而传统统计模型如ARIMA、指数平滑具有透明的数学结构。

解决方案是采用残差学习架构：传统模型先捕获线性成分，包括趋势和季节性；然后Time-LLM学习残差中的非线性模式。最终预测等于线性预测加上非线性预测。

这种设计的优势在于：既发挥了传统模型的可解释性，又利用了LLM捕获复杂模式的能力。适用场景为周期性明显的数据，如ETT电力负荷数据集和Traffic交通流量数据集。

---

## 第十一页：创新点二 - 分段自适应融合

创新点二针对的问题是：输入序列的不同区间可能呈现不同模式，比如前半段平稳、后半段剧烈波动，固定权重的融合无法适应这种变化。

解决方案是设计分段模式检测器，检测每段的周期性、趋势性、噪声水平等特征，动态分配传统模型与Time-LLM的权重。检测指标包括ADF平稳性检验、FFT能量集中度、线性回归斜率等。

适用场景为非平稳时序和模式变化剧烈的数据，能够输出各段的模式判断与权重分配报告，增强可解释性。

---

## 第十二页：创新点三 - 变量间注意力增强

创新点三针对的问题是：Time-LLM将多变量展平为独立样本处理，完全忽略了变量间的相关性。而实际数据中，变量间往往存在强关联，例如电力负荷中有功功率和无功功率的相关性。

解决方案是在Reprogramming Layer后添加Inter-Variate Attention模块，在变量维度进行注意力计算，捕获多变量相关性。这一设计灵感来源于ICLR 2024的Spotlight论文iTransformer。

适用场景为多变量预测任务，以及变量间存在强相关性的数据集。该模块还可以输出变量重要性权重，作为可解释性的一部分。

---

## 第十三页：创新点四 - 频域增强

创新点四针对的问题是：时序数据通常包含趋势和周期成分，在时域直接处理可能混淆这两种模式。

解决方案是在Patching之前通过FFT将信号分解为低频趋势成分和高频季节性成分，分别用不同参数的分支处理，然后融合输出。这一设计灵感来源于TimesNet的频域分解思想。

适用场景为具有明显周期特征的数据集，如ETTh小时级数据具有24小时和168小时的周期，Weather数据集具有明显的季节性特征。

---

## 第十四页：创新点五 - 动态Prompt生成

创新点五针对的问题是：现有的统计信息提示词是全局的，无法反映序列内的局部变化。当数据分布突变时，静态Prompt无法感知，缺乏针对具体样本的动态调整能力。

解决方案是在Prompt构建阶段引入分层动态生成机制。具体包括：局部统计特征编码，检测分段的趋势和波动变化；可学习的Prompt Encoder；以及门控融合机制，将静态文本Prompt与数据驱动的动态嵌入相结合。

适用场景为ETT数据集中的节假日或季节转换时段、Weather数据集的极端天气时段、Traffic数据集的交通高峰与低谷转换等。

---

## 第十五页：后续计划

后续工作计划如下：

1月底前，完成论文内容撰写，详细阐述课题意义、技术原理、代码框架和复现过程。

2月中旬前，完成创新模块的代码实现，重点是残差学习架构和分段自适应融合。

寒假期间，争取课题组的算力资源，在更大参数量的模型上进行验证。

后续将进行消融实验，验证各创新点的有效性；进行对比实验，与PatchTST、iTransformer等基线模型比较；并考虑将模型应用于实际工程场景。

---

## 第十六页：研究成果价值展望

本课题的研究成果预期在以下方面产生价值：

学术价值方面，提出可解释的混合预测框架，为LLM时序预测领域贡献新方法，具备投稿国内会议或期刊的研究基础。

应用价值方面，在电力负荷预测、交通流量预测等场景提供可解释的预测依据，增强预测结果的可信度。

延伸价值方面，为多模态融合以及通用人工智能在垂直领域的应用提供技术参考，探索AGI模型在非语言领域的适配潜力。

---

## 第十七页：参考文献

本课题参考的主要文献包括：PatchTST提出的Patch时序分割方法，TimesNet的频域二维变换，iTransformer的变量维度注意力机制，Time-LLM的LLM重编程时序预测框架，以及TimeMixer、N-BEATS、AutoTimes、Time-MoE等近年来的代表性工作。这些文献为本课题的创新设计提供了重要的理论支撑和方法借鉴。

---

## 第十八页：致谢

以上就是我的汇报内容。本课题以Time-LLM为基础，针对其可解释性不足的问题，设计了五项创新模块，将传统统计模型的可解释性与大语言模型的强大模式识别能力相融合。目前已完成环境搭建、论文复现和创新方案设计，后续将重点推进代码实现和实验验证。

感谢各位老师的聆听，欢迎各位老师批评指正！

---

## 附录：时间控制参考

| 页码 | 内容 | 建议时长 |
|------|------|----------|
| 1-2 | 封面+目录 | 15秒 |
| 3 | 研究背景 | 25秒 |
| 4 | 项目理解 | 30秒 |
| 5 | 可训练参数 | 20秒 |
| 6 | 研究现状 | 30秒 |
| 7 | 技术路线 | 25秒 |
| 8 | 当前工作 | 25秒 |
| 9 | 创新点概述 | 15秒 |
| 10-14 | 五项创新点 | 100秒（每项20秒） |
| 15 | 后续计划 | 20秒 |
| 16 | 价值展望 | 20秒 |
| 17-18 | 参考文献+致谢 | 15秒 |
| **总计** | | **约340秒（5分40秒）** |

---

**字数统计：约 2100 字**
**预计汇报时长：5-6 分钟**
