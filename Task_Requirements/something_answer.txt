1.汇报术语-项目流程
运行项目代码本身没有什么问题，因为算力有限，跑了一轮。
2.显存问题-最终报告
第一个问题：训练时间长，且epoch过少无法验证效果。
且无法验证改进创新点效果。
四个训练参数。相对要求较低。
验证超参数的集合，只起到了验证10个epoch防止过拟合？
对于任务书中的要求有点疑惑，是复现？论文中说明原理？需要在别的项目更换数据集复现？
有所创新自然是好，能用到某一个idea就可以。
看看之前提供的优秀范文。
数据特性-选择模型
可以看做时间x数据y。
依据数据模型，可以看出是否相对符合相应维度。其次则投票。
以及是否符合相应传统模型，或在输出端训练理解短期必要的传统模型。
3.慎重选择/加入提示词-考虑到纯数据的单薄与独特-纯数据预测难以泛化
是否需要加入提示词，何时加入。
提示词是否准确的起到了提示的作用，是否强加因果/造成干扰。
作为时序预测，纯数据，有其不同于其他多模态的特殊性。小规模llm可用，特定垂直模型可用，可以偏向nlp映射拟合。


4.思考保留的点
训练了多少层，保留了多少参数，保留了哪些参数，用的是编码/解码，即数据整体流转过程。
5.针对timellm输出端训练-选择-结合传统模型的若干创新点及提升
传统的时序预测，针对输入数据设置模型。可以简单的线性预测，当然，一般是设计成非线性模型处理。
传统的模型不能丢，可以将其训练成果丢给大模型作为参考，让大模型训练出什么条件下，即什么数据类型（+必要提示词）可以去使用相关数据，以增强准确性。
这个创新(针对特定数据融合传统模型)是个体力活。我最近在做一个项目，即学生教学。（固然可以使之个性化针对错题）（可不提）（更通常是像物理一样，设置若干模板，也可以在“暴露问题”后选择相应的模板教学）类比斟酌。
且工程上也可行。因为可以看作两个（大/小）模型的（并行）协同处理，效果会保持或者有所提升（不应该下降，而且即使不是创新，也是缝缝补补的权宜之计。）
6.毕设问题思考-解释创新-扩展亮点
提示词再“编码”可以理解，有加有舍。数据本身是要有一组一组，比如平均，最高，这些是在哪些部分？是提示词。这些是和指令一起作为提示词。也去进行映射还是看做提示词。是致敬映射时会有增长，缓慢上升之类的nlp，最后也不是纯粹的nlp语言了。看那些在代码中也有的平均值，最高，是拿这些特征值去进行的和nlp混合映射吗？不是，数字本身会进行相应的映射。
我考虑过informer的结构，也是大语言模型进行预测的很著名的论文。这篇文章是通过结构的优化相当于使之更适合处理patch类型的数据，可解释性不如timellm。timellm有提示词说明原因，也有平均值，最高值这些特征数据（这些重点思考），（可以思考一下这里的解释性，体征数据可以及时反应当前范围情况且和提示词相印证），应该是数字-数字向量-llm理解到数字向量中的上升下降-和nlp向量进行混合“交融”，倾向这里的，代码中可见的，运算出来的特征数据偏向设定为提示词。想过进行结构的增进，这个可移植。
Timellm中提到是“交融”，我认为更是类似于一种映射后的加权，从一个有些陌生的领域耦合解耦后到我们熟悉的，可以解决的领域。
个人对这个有所想法，因为思考过，我们认知，或者说在现有的transformer架构下，大模型去计算可能，这样就需要我们去用token来描述这个世界。纯数字堆叠，即使是人脑去进行相应的推理，也是很难看出来含义。但是转化为nlp，或者说和nlp“交融”，相当于我们为大语言模型描述出某个特定的领域，然后发挥出他的作用。作为人类感知世界，可能有思考有直觉，可以语言可以图像，但是真正经过人脑分析再表达以后，目前的主流还是“描述”。所以nlp是，要预测的数据是，或者说图像视频，我们要将ai真正进入世界的多模态的完善的过程，可以在某一领域进行这种单通道的侧重映射。起码目前看，大语言模型在nlp方面的性能得到验证和应用。
7.训练步骤-涉及训练类型推理及其创新点
实际推理四个部分，patch 词汇表 reprogramming 输出层映射
本质上它是利用大模型的一个应用，
它比别的时序预测模型多了相对可解释性的部分，因为涉及语义映射和提示词（原因添加与人为总结）
但是不涉及大模型的算法和神经网络，所以基本上训练过程就是一头一尾（可以说词汇表，重编码和输出映射），训练的层数和算力代价相对直观可用。
便于小规模数据集的垂直应用和具体适配。以起到类似微调的效果。
8.思考多模态两条方向
a.归纳为llm的文本token模块
b.两个模态模型，相互相对独立
9.榨干数据全部信息
进行时序预测，就是要榨干数据的全部信息。
包括多重，多维度的周期分量挖掘。
在得到结果时，能否去比较或融合不同周期下的结果，进而放大数据作用，增强结果可信性（可解释性）。


推理时，可以规定在什么特征下使用什么周期的推理。
且可以多个周期均使用。即投票。
考虑规定和投票的选择。什么情况下使用哪种。
10.数据周期维度与patch-对象（时间步长）与patch分组与batch
选取数据周期，以最大发挥数据作用。
且动态调整。考虑推理时是否可以选择。考虑动态选择过程。
选取的周期，叠加，选取，和patch是否有关，是否可以有所关联。
核心还想在于传统模型的靠拢，训练。
选择周期，动态调整patch，根据数据特征（准确率选择周期）-根据数据特征选择（传统模型传统方式）模型（进行匹配模型修正）-正规nlp预测（生成式输出）都是可以看作算，数据训练以进行最有可能，最“合适”的输出。



512个时间步为一个对象。取对象时仅相聚1，在训练集中取到了近14000个对象。
这里错误了，是一个对象内以16个时间步划分patch了。每个patch之间互相重叠8个时间步。互相重叠8个时间步即可保证数据最大利用且相对互相关联。（也有可能过分收敛）
没有也无需“分块”“组合”“分块组合”的概念。
将对象16个为一个“分块组合”，每个“分块组合”之间重叠（s）8个对象。
64个对象构成一个patch（“分块组合”为patch内部分块）。


对patch进行每次epoch之前的每次打乱（一维打乱）是针对patch进行的。batch一次是n（这里设定为4）个patch，每个patch中是以对象/“分块对象？”为单位进行逐个训练（应该是对象为单位按顺序训练，但“分块单位”作用在哪里）。所以无此“分块组合”。
推理时只是不进行反向传播。其余分块，传递，数据维度应和训练相同。


读完论文后，复现，先了解项目架构，因为标准论文文件命名和类名都符合论文思想，再了解数据流动，主要是数据维度变换过程，基本上就比较理解，有助于后续创新改进。
了解到四个训练参数，输入数据展开卷积，词汇表，重编码，输出线性映射。
正常模型词汇表是针对整个常用语料，我们词汇表精简，减少训练。也可以看做是专有模型，垂直领域的部分应用。不同的项目训练出来的词汇表是不一致的。更好的匹配专业，项目专业方向。

