# Time-LLM åˆ›æ–°æ”¹è¿›æ–¹æ¡ˆ (Innovation Proposals)

> **ç›®æ ‡**: åœ¨ Time-LLM æ¡†æ¶åŸºç¡€ä¸Šï¼Œå‚è€ƒ TimesNetã€iTransformerã€PatchTSTã€TimeMixerã€Time-MoE ç­‰æœ€æ–°æ¨¡å‹ï¼Œæå‡ºå¯è¡Œçš„åˆ›æ–°æ”¹è¿›æ–¹æ¡ˆ
> **å‚è€ƒæ–‡çŒ®**: ICLR 2024-2025 é¡¶ä¼šè®ºæ–‡

---

## ä¸€ã€å½“å‰ Time-LLM æ¶æ„åˆ†æ

### 1.1 æ ¸å¿ƒæœºåˆ¶å›é¡¾

```
æ—¶åºæ•°æ® â†’ [Patching] â†’ [Reprogramming Layer] â†’ [Frozen LLM] â†’ [Output Projection] â†’ é¢„æµ‹ç»“æœ
             â†‘                    â†‘
         å±€éƒ¨æ¨¡å¼æå–         è·¨æ¨¡æ€å¯¹é½
```

### 1.2 ç°æœ‰å±€é™æ€§

| é—®é¢˜ | æè¿° | å½±å“ |
|------|------|------|
| **å•å°ºåº¦ Patching** | ä»…ä½¿ç”¨å›ºå®š patch_len=16, stride=8 | æ— æ³•æ•è·å¤šå°ºåº¦æ—¶åºæ¨¡å¼ |
| **é€šé“ç‹¬ç«‹å¤„ç†** | å¤šå˜é‡è¢«å±•å¹³ä¸ºç‹¬ç«‹æ ·æœ¬å¤„ç† | å¿½ç•¥å˜é‡é—´ç›¸å…³æ€§ |
| **é™æ€ Prompt** | ç»Ÿè®¡ä¿¡æ¯æç¤ºç¼ºä¹åŠ¨æ€è°ƒæ•´ | éš¾ä»¥é€‚åº”éå¹³ç¨³æ—¶åº |
| **å•ä¸€ LLM å±‚** | ä»…ä½¿ç”¨ LLM éƒ¨åˆ†å±‚ | å¯èƒ½æµªè´¹æ·±å±‚è¯­ä¹‰èƒ½åŠ› |
| **è®¡ç®—æ•ˆç‡** | å¤§ LLM æ¨ç†å¼€é”€å¤§ | å®æ—¶åœºæ™¯å—é™ |

---

## äºŒã€åˆ›æ–°æ–¹æ¡ˆä¸€: å¤šå°ºåº¦åˆ†è§£æ··åˆ (Multi-Scale Decomposition Mixing)

### 2.1 åˆ›æ–°åŸç†

**çµæ„Ÿæ¥æº**: [TimeMixer (ICLR 2024)](https://github.com/kwuking/TimeMixer) çš„å¤šå°ºåº¦åˆ†è§£æ€æƒ³

TimeMixer è¯æ˜äº†æ—¶åºæ•°æ®åœ¨ä¸åŒå°ºåº¦ä¸‹å±•ç°ä¸åŒæ¨¡å¼:
- **ç»†ç²’åº¦**: æ•è·å±€éƒ¨æ³¢åŠ¨ã€å™ªå£°
- **ç²—ç²’åº¦**: æ•è·è¶‹åŠ¿ã€å‘¨æœŸæ€§

**æ ¸å¿ƒæ€æƒ³**: å°† Time-LLM çš„å•å°ºåº¦ Patching æ‰©å±•ä¸ºå¤šå°ºåº¦åˆ†è§£ï¼Œç„¶ååœ¨ LLM å†…éƒ¨è¿›è¡Œå°ºåº¦æ··åˆã€‚

### 2.2 æ¶æ„è®¾è®¡

```
åŸå§‹æ—¶åº
    â”‚
    â”œâ”€â”€ [ä¸‹é‡‡æ · 1x] â†’ Patch Embedding (ç»†ç²’åº¦) â†’ Reprogramming â†’ LLM Layer 1-2
    â”‚
    â”œâ”€â”€ [ä¸‹é‡‡æ · 2x] â†’ Patch Embedding (ä¸­ç²’åº¦) â†’ Reprogramming â†’ LLM Layer 3-4
    â”‚
    â””â”€â”€ [ä¸‹é‡‡æ · 4x] â†’ Patch Embedding (ç²—ç²’åº¦) â†’ Reprogramming â†’ LLM Layer 5-6
                                                                    â”‚
                                                                    â–¼
                                                        [Multi-Scale Fusion]
                                                                    â”‚
                                                                    â–¼
                                                              é¢„æµ‹è¾“å‡º
```

### 2.3 ä»£ç ä¿®æ”¹ä½ç½®

**æ–‡ä»¶**: `models/TimeLLM.py`

```python
# æ–°å¢: å¤šå°ºåº¦åˆ†è§£æ¨¡å— (åœ¨ class Model ä¸­æ·»åŠ )
class MultiScaleDecomposition(nn.Module):
    """å¤šå°ºåº¦æ—¶åºåˆ†è§£"""
    def __init__(self, scales=[1, 2, 4]):
        super().__init__()
        self.scales = scales
        self.downsamples = nn.ModuleList([
            nn.AvgPool1d(kernel_size=s, stride=s) if s > 1 else nn.Identity()
            for s in scales
        ])

    def forward(self, x):
        # x: [B, T, N]
        outputs = []
        for ds in self.downsamples:
            x_ds = ds(x.permute(0, 2, 1)).permute(0, 2, 1)  # [B, T/s, N]
            outputs.append(x_ds)
        return outputs  # List of [B, T/s, N]

# ä¿®æ”¹: forward æ–¹æ³•ä¸­æ·»åŠ å¤šå°ºåº¦å¤„ç†
def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):
    # å¤šå°ºåº¦åˆ†è§£
    multi_scale_inputs = self.multi_scale_decomp(x_enc)

    # æ¯ä¸ªå°ºåº¦ç‹¬ç«‹å¤„ç†
    multi_scale_outputs = []
    for scale_idx, x_scale in enumerate(multi_scale_inputs):
        # Patching for this scale
        enc_out, _ = self.patch_embedding(x_scale)
        # Reprogramming
        enc_out = self.reprogramming_layer(enc_out, ...)
        # Use different LLM layers for different scales
        start_layer = scale_idx * 2
        end_layer = start_layer + 2
        for layer in self.llm_layers[start_layer:end_layer]:
            enc_out = layer(enc_out)
        multi_scale_outputs.append(enc_out)

    # Fusion
    output = self.multi_scale_fusion(multi_scale_outputs)
    return output
```

### 2.4 é¢„æœŸæ•ˆæœ

- **MSE é™ä½**: é¢„è®¡ 5-10%ï¼Œå°¤å…¶åœ¨é•¿å‘¨æœŸæ•°æ®é›† (ETTh1/h2)
- **é²æ£’æ€§æå‡**: å¯¹å™ªå£°å’Œå¼‚å¸¸å€¼æ›´é²æ£’
- **å‚æ•°å¢åŠ **: çº¦ 20%ï¼Œä½†æ¨ç†æ—¶é—´å¢åŠ æœ‰é™

---

## ä¸‰ã€åˆ›æ–°æ–¹æ¡ˆäºŒ: å˜é‡é—´æ³¨æ„åŠ›å¢å¼º (Inter-Variate Attention)

### 3.1 åˆ›æ–°åŸç†

**çµæ„Ÿæ¥æº**: [iTransformer (ICLR 2024)](https://arxiv.org/abs/2310.06625)

iTransformer å‘ç°:
- åŸå§‹ Transformer åœ¨æ—¶é—´ç»´åº¦åš attentionï¼Œå¿½ç•¥å˜é‡ç›¸å…³æ€§
- **åè½¬æ€è·¯**: åœ¨å˜é‡ç»´åº¦åš attentionï¼Œæ¯ä¸ªå˜é‡ä½œä¸ºä¸€ä¸ª token

**æ ¸å¿ƒæ€æƒ³**: åœ¨ Time-LLM çš„ Reprogramming åæ·»åŠ  Inter-Variate Attention æ¨¡å—ã€‚

### 3.2 æ¶æ„è®¾è®¡

```
Patch Embeddings [B*N, num_patches, d_model]
            â”‚
            â–¼
    [Reprogramming Layer]
            â”‚
            â–¼
    [B*N, num_patches, llm_dim]
            â”‚
            â–¼
    [Reshape to [B, N, num_patches, llm_dim]]
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inter-Variate Attention          â”‚
â”‚  Query/Key/Value: å˜é‡ç»´åº¦ N      â”‚
â”‚  æ•è·: å˜é‡é—´ç›¸å…³æ€§               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    [Reshape back to [B*N, num_patches, llm_dim]]
            â”‚
            â–¼
        [LLM Forward]
```

### 3.3 ä»£ç ä¿®æ”¹ä½ç½®

**æ–‡ä»¶**: `models/TimeLLM.py`

```python
# æ–°å¢: å˜é‡é—´æ³¨æ„åŠ›æ¨¡å—
class InterVariateAttention(nn.Module):
    """æ•è·å¤šå˜é‡ä¹‹é—´çš„ç›¸å…³æ€§"""
    def __init__(self, d_model, n_heads=8, dropout=0.1):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim=d_model,
            num_heads=n_heads,
            dropout=dropout,
            batch_first=True
        )
        self.norm = nn.LayerNorm(d_model)

    def forward(self, x, n_vars):
        # x: [B*N, num_patches, d_model]
        B_N, num_patches, d_model = x.shape
        B = B_N // n_vars

        # Reshape: [B, N, num_patches, d_model] -> [B*num_patches, N, d_model]
        x = x.view(B, n_vars, num_patches, d_model)
        x = x.permute(0, 2, 1, 3).reshape(B * num_patches, n_vars, d_model)

        # Inter-variate attention (åœ¨å˜é‡ç»´åº¦ N ä¸Šåš attention)
        attn_out, _ = self.attention(x, x, x)
        x = self.norm(x + attn_out)

        # Reshape back: [B*num_patches, N, d_model] -> [B*N, num_patches, d_model]
        x = x.view(B, num_patches, n_vars, d_model).permute(0, 2, 1, 3)
        x = x.reshape(B * n_vars, num_patches, d_model)

        return x

# åœ¨ forward ä¸­è°ƒç”¨
enc_out = self.reprogramming_layer(enc_out, source_embeddings, source_embeddings)
enc_out = self.inter_variate_attn(enc_out, n_vars)  # æ–°å¢
```

### 3.4 é¢„æœŸæ•ˆæœ

- **å¤šå˜é‡é¢„æµ‹æå‡**: MSE é™ä½ 8-15%ï¼Œç‰¹åˆ«æ˜¯ `features=M` åœºæ™¯
- **å‚æ•°å¢åŠ **: çº¦ 5%
- **é€‚ç”¨åœºæ™¯**: å˜é‡é—´æœ‰å¼ºç›¸å…³æ€§çš„æ•°æ®é›† (å¦‚ Traffic, Electricity)

---

## å››ã€åˆ›æ–°æ–¹æ¡ˆä¸‰: åŠ¨æ€ Prompt ç”Ÿæˆ (Dynamic Prompt Generation)

### 4.1 åˆ›æ–°åŸç†

**çµæ„Ÿæ¥æº**: [AutoTimes (NeurIPS 2024)](https://arxiv.org/abs/2402.02370) çš„è‡ªå›å½’ prompt æ€æƒ³

å½“å‰ Time-LLM çš„ Prompt æ˜¯é™æ€çš„ç»Ÿè®¡ä¿¡æ¯:
- `min_value, max_value, median, trend, top-5 lags`

**å±€é™æ€§**:
- æ— æ³•æ•è·æ—¶åºçš„éå¹³ç¨³æ€§å˜åŒ–
- å¯¹åˆ†å¸ƒæ¼‚ç§» (Distribution Shift) ä¸æ•æ„Ÿ

**æ ¸å¿ƒæ€æƒ³**: ä½¿ç”¨å¯å­¦ä¹ çš„ Prompt Encoder åŠ¨æ€ç”Ÿæˆ prompt embeddingsã€‚

### 4.2 æ¶æ„è®¾è®¡

```
åŸå§‹æ—¶åº x_enc
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                  â”‚
      â–¼                                  â–¼
[ç»Ÿè®¡ç‰¹å¾æå–]                    [Prompt Encoder (å¯å­¦ä¹ )]
  min/max/median/...                    â”‚
      â”‚                                  â”‚
      â–¼                                  â–¼
[Text Tokenizer]              [Learned Prompt Tokens]
      â”‚                                  â”‚
      â–¼                                  â–¼
[Static Prompt Emb]           [Dynamic Prompt Emb]
      â”‚                                  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        [Prompt Fusion (Attention)]
                 â”‚
                 â–¼
           Final Prompt Embeddings
```

### 4.3 ä»£ç ä¿®æ”¹ä½ç½®

**æ–‡ä»¶**: `models/TimeLLM.py`

```python
# æ–°å¢: åŠ¨æ€ Prompt ç¼–ç å™¨
class DynamicPromptEncoder(nn.Module):
    """ä»æ—¶åºæ•°æ®ç›´æ¥å­¦ä¹  prompt embeddings"""
    def __init__(self, seq_len, n_vars, llm_dim, num_prompt_tokens=32):
        super().__init__()
        self.num_tokens = num_prompt_tokens

        # æ—¶åºç¼–ç å™¨
        self.temporal_encoder = nn.Sequential(
            nn.Linear(seq_len, 256),
            nn.GELU(),
            nn.Linear(256, num_prompt_tokens * llm_dim)
        )

        # å¯å­¦ä¹ çš„åŸºç¡€ prompt tokens
        self.base_prompt = nn.Parameter(torch.randn(1, num_prompt_tokens, llm_dim))

        # Fusion gate
        self.fusion_gate = nn.Sequential(
            nn.Linear(llm_dim * 2, llm_dim),
            nn.Sigmoid()
        )

    def forward(self, x_enc):
        # x_enc: [B, T, N]
        B, T, N = x_enc.shape

        # ç”ŸæˆåŠ¨æ€ prompt: [B, num_tokens, llm_dim]
        x_flat = x_enc.mean(dim=-1)  # [B, T]
        dynamic_prompt = self.temporal_encoder(x_flat)
        dynamic_prompt = dynamic_prompt.view(B, self.num_tokens, -1)

        # ä¸åŸºç¡€ prompt èåˆ
        base_prompt = self.base_prompt.expand(B, -1, -1)
        combined = torch.cat([dynamic_prompt, base_prompt], dim=-1)
        gate = self.fusion_gate(combined)

        output = gate * dynamic_prompt + (1 - gate) * base_prompt
        return output

# åœ¨ forward ä¸­æ›¿æ¢é™æ€ prompt
# åŸå§‹: prompt_embeddings = self.llm_model.get_input_embeddings()(prompt)
# ä¿®æ”¹ä¸º:
static_prompt_emb = self.llm_model.get_input_embeddings()(prompt)
dynamic_prompt_emb = self.dynamic_prompt_encoder(x_enc)
prompt_embeddings = self.prompt_fusion(static_prompt_emb, dynamic_prompt_emb)
```

### 4.4 é¢„æœŸæ•ˆæœ

- **éå¹³ç¨³æ—¶åºæ€§èƒ½æå‡**: MSE é™ä½ 10-20%
- **è¿ç§»èƒ½åŠ›å¢å¼º**: è·¨æ•°æ®é›†æ³›åŒ–æ›´å¥½
- **å‚æ•°å¢åŠ **: çº¦ 15%

---

## äº”ã€åˆ›æ–°æ–¹æ¡ˆå››: ç¨€ç–ä¸“å®¶æ··åˆ (Mixture of Experts for Time-LLM)

### 5.1 åˆ›æ–°åŸç†

**çµæ„Ÿæ¥æº**: [Time-MoE (ICLR 2025 Spotlight)](https://github.com/Time-MoE/Time-MoE)

Time-MoE è¯æ˜äº†:
- MoE æ¶æ„å¯ä»¥åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶å¤§å¹…æ‰©å±•æ¨¡å‹å®¹é‡
- 2.4B å‚æ•°æ¨¡å‹ä»…æ¿€æ´» 1B å‚æ•°ï¼Œæ˜¾å­˜éœ€æ±‚ < 8GB

**æ ¸å¿ƒæ€æƒ³**: åœ¨ Time-LLM çš„ Reprogramming Layer åæ·»åŠ  MoE å±‚ã€‚

### 5.2 æ¶æ„è®¾è®¡

```
Reprogrammed Embeddings [B*N, num_patches, llm_dim]
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Mixture of Experts Layer         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Router: è®¡ç®—æ¯ä¸ª patch çš„      â”‚   â”‚
â”‚  â”‚  expert åˆ†é…æ¦‚ç‡                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚    â–¼      â–¼      â–¼      â–¼              â”‚
â”‚  Expert1 Expert2 Expert3 Expert4       â”‚
â”‚  (Trend) (Season)(Short) (Long)        â”‚
â”‚    â”‚      â”‚      â”‚      â”‚              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚           â”‚                             â”‚
â”‚           â–¼                             â”‚
â”‚    [Top-K Sparse Selection]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
            LLM Forward
```

### 5.3 ä»£ç ä¿®æ”¹ä½ç½®

**æ–‡ä»¶**: `models/TimeLLM.py`

```python
# æ–°å¢: ç¨€ç–ä¸“å®¶æ··åˆå±‚
class TimeSeriesMoE(nn.Module):
    """æ—¶åºä¸“ç”¨çš„ MoE å±‚"""
    def __init__(self, d_model, num_experts=4, top_k=2, dropout=0.1):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k

        # Router: å†³å®šä½¿ç”¨å“ªäº›ä¸“å®¶
        self.router = nn.Linear(d_model, num_experts)

        # Experts: æ¯ä¸ªä¸“å®¶ä¸“æ³¨äºä¸åŒçš„æ—¶åºæ¨¡å¼
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_model * 4),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(d_model * 4, d_model)
            ) for _ in range(num_experts)
        ])

        self.norm = nn.LayerNorm(d_model)

    def forward(self, x):
        # x: [B, L, D]
        B, L, D = x.shape

        # è®¡ç®— router æ¦‚ç‡
        router_logits = self.router(x)  # [B, L, num_experts]
        router_probs = F.softmax(router_logits, dim=-1)

        # Top-K é€‰æ‹©
        top_k_probs, top_k_indices = torch.topk(router_probs, self.top_k, dim=-1)
        top_k_probs = top_k_probs / top_k_probs.sum(dim=-1, keepdim=True)

        # ç¨€ç–æ¿€æ´»ä¸“å®¶
        output = torch.zeros_like(x)
        for i in range(self.top_k):
            expert_idx = top_k_indices[:, :, i]  # [B, L]
            prob = top_k_probs[:, :, i:i+1]  # [B, L, 1]

            for e_idx in range(self.num_experts):
                mask = (expert_idx == e_idx)  # [B, L]
                if mask.any():
                    expert_input = x[mask]
                    expert_output = self.experts[e_idx](expert_input)
                    output[mask] += prob[mask].squeeze(-1).unsqueeze(-1) * expert_output

        return self.norm(x + output)

# åœ¨æ¨¡å‹ä¸­ä½¿ç”¨
self.moe_layer = TimeSeriesMoE(d_model=llm_dim, num_experts=4, top_k=2)
# forward ä¸­:
enc_out = self.reprogramming_layer(enc_out, ...)
enc_out = self.moe_layer(enc_out)  # æ–°å¢
```

### 5.4 é¢„æœŸæ•ˆæœ

- **æ¨¡å‹å®¹é‡å¤§å¹…æå‡**: 4x ä¸“å®¶ = 4x å®¹é‡ï¼Œä½†åªæ¿€æ´» 2x
- **è®¡ç®—æ•ˆç‡**: æ¨ç†æ—¶é—´ä»…å¢åŠ çº¦ 30%
- **é•¿åºåˆ—æ€§èƒ½**: ç‰¹åˆ«é€‚åˆ `pred_len=720` çš„é•¿æœŸé¢„æµ‹

---

## å…­ã€åˆ›æ–°æ–¹æ¡ˆäº”: é¢‘åŸŸå¢å¼º (Frequency Domain Enhancement)

### 6.1 åˆ›æ–°åŸç†

**çµæ„Ÿæ¥æº**: [TimesNet (ICLR 2023)](https://arxiv.org/abs/2210.02186) çš„ 2D å˜æ¢æ€æƒ³

TimesNet å°†æ—¶åºè½¬æ¢ä¸º 2D è¡¨ç¤º:
- è¡Œ: å‘¨æœŸå†…çš„ä½ç½®
- åˆ—: å‘¨æœŸæ•°

**æ ¸å¿ƒæ€æƒ³**: åœ¨ Patching å‰æ·»åŠ é¢‘åŸŸåˆ†è§£ï¼Œåˆ†ç¦»è¶‹åŠ¿å’Œå‘¨æœŸæˆåˆ†ã€‚

### 6.2 æ¶æ„è®¾è®¡

```
åŸå§‹æ—¶åº x_enc [B, T, N]
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FFT é¢‘åŸŸåˆ†è§£                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ä½é¢‘æˆåˆ†   â”‚ é«˜é¢‘æˆåˆ†   â”‚    â”‚
â”‚  â”‚ (è¶‹åŠ¿)     â”‚ (å­£èŠ‚æ€§)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚
        â–¼              â–¼
  [Trend Branch]  [Seasonal Branch]
        â”‚              â”‚
        â–¼              â–¼
  [Patch + Repr]  [Patch + Repr]
        â”‚              â”‚
        â–¼              â–¼
    [LLM Trend]   [LLM Seasonal]
        â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        [Feature Fusion]
               â”‚
               â–¼
          æœ€ç»ˆé¢„æµ‹
```

### 6.3 ä»£ç ä¿®æ”¹ä½ç½®

**æ–‡ä»¶**: `models/TimeLLM.py`

```python
# æ–°å¢: é¢‘åŸŸåˆ†è§£æ¨¡å—
class FrequencyDecomposition(nn.Module):
    """åŸºäº FFT çš„è¶‹åŠ¿-å­£èŠ‚æ€§åˆ†è§£"""
    def __init__(self, top_k_freqs=5):
        super().__init__()
        self.top_k = top_k_freqs

    def forward(self, x):
        # x: [B, T, N]
        B, T, N = x.shape

        # FFT å˜æ¢
        x_fft = torch.fft.rfft(x, dim=1)
        freqs = torch.fft.rfftfreq(T, device=x.device)

        # åˆ†ç¦»ä½é¢‘ (è¶‹åŠ¿) å’Œé«˜é¢‘ (å­£èŠ‚æ€§)
        amplitude = torch.abs(x_fft)

        # Top-K ä¸»è¦é¢‘ç‡
        _, top_indices = torch.topk(amplitude.mean(dim=(0, 2)), self.top_k)

        # ä½é¢‘æˆåˆ† (è¶‹åŠ¿)
        mask_low = torch.zeros_like(x_fft)
        mask_low[:, :3, :] = 1  # ä¿ç•™å‰3ä¸ªä½é¢‘
        trend = torch.fft.irfft(x_fft * mask_low, n=T, dim=1)

        # é«˜é¢‘æˆåˆ† (å­£èŠ‚æ€§)
        seasonal = x - trend

        return trend, seasonal

# åœ¨ forward ä¸­ä½¿ç”¨
trend, seasonal = self.freq_decomp(x_enc)

# åˆ†åˆ«å¤„ç†
trend_out = self.forward_branch(trend, "trend")
seasonal_out = self.forward_branch(seasonal, "seasonal")

# èåˆ
output = self.fusion_layer(trend_out, seasonal_out)
```

### 6.4 é¢„æœŸæ•ˆæœ

- **å‘¨æœŸæ€§æ•°æ®é›†æå‡æ˜¾è‘—**: ETTh1/h2 MSE é™ä½ 10-15%
- **å¯è§£é‡Šæ€§å¢å¼º**: å¯è§†åŒ–è¶‹åŠ¿å’Œå­£èŠ‚æ€§æˆåˆ†
- **è®¡ç®—å¼€é”€**: FFT éå¸¸é«˜æ•ˆï¼Œé¢å¤–å¼€é”€ < 5%

---

## ä¸ƒã€å®ç°ä¼˜å…ˆçº§å»ºè®®

| æ–¹æ¡ˆ | éš¾åº¦ | é¢„æœŸæ”¶ç›Š | ä¼˜å…ˆçº§ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|--------|---------|
| **æ–¹æ¡ˆäºŒ: å˜é‡é—´æ³¨æ„åŠ›** | â­â­ | 8-15% MSEâ†“ | ğŸ¥‡ æœ€é«˜ | å¤šå˜é‡é¢„æµ‹ |
| **æ–¹æ¡ˆäº”: é¢‘åŸŸå¢å¼º** | â­â­ | 10-15% MSEâ†“ | ğŸ¥ˆ é«˜ | å‘¨æœŸæ€§æ•°æ® |
| **æ–¹æ¡ˆä¸€: å¤šå°ºåº¦åˆ†è§£** | â­â­â­ | 5-10% MSEâ†“ | ğŸ¥‰ ä¸­ | é•¿åºåˆ—é¢„æµ‹ |
| **æ–¹æ¡ˆä¸‰: åŠ¨æ€ Prompt** | â­â­â­ | 10-20% MSEâ†“ | ä¸­ | éå¹³ç¨³æ—¶åº |
| **æ–¹æ¡ˆå››: MoE** | â­â­â­â­ | æ¨¡å‹å®¹é‡æå‡ | ä½ | å¤§è§„æ¨¡éƒ¨ç½² |

---

## å…«ã€å®éªŒè®¾è®¡å»ºè®®

### 8.1 æ¶ˆèå®éªŒ

```bash
# åŸºçº¿
python run_main.py --model TimeLLM --data ETTh1 --pred_len 96

# + å˜é‡é—´æ³¨æ„åŠ›
python run_main.py --model TimeLLM --data ETTh1 --pred_len 96 --use_inter_variate_attn

# + é¢‘åŸŸå¢å¼º
python run_main.py --model TimeLLM --data ETTh1 --pred_len 96 --use_freq_decomp

# + å…¨éƒ¨æ”¹è¿›
python run_main.py --model TimeLLM --data ETTh1 --pred_len 96 --use_all_improvements
```

### 8.2 å¯¹æ¯”å®éªŒ

| æ¨¡å‹ | ETTh1 MSE | ETTh2 MSE | ETTm1 MSE | ETTm2 MSE |
|------|-----------|-----------|-----------|-----------|
| Time-LLM (åŸºçº¿) | 0.375 | 0.288 | 0.302 | 0.175 |
| + Inter-Variate | ? | ? | ? | ? |
| + Frequency | ? | ? | ? | ? |
| + All | ? | ? | ? | ? |
| iTransformer | 0.386 | 0.297 | 0.334 | 0.180 |
| TimeMixer | 0.370 | 0.281 | 0.299 | 0.170 |

---

## ä¹ã€å‚è€ƒèµ„æº

### 9.1 è®ºæ–‡

- [Time-LLM (ICLR 2024)](https://arxiv.org/abs/2310.01728)
- [iTransformer (ICLR 2024)](https://arxiv.org/abs/2310.06625)
- [TimeMixer (ICLR 2024)](https://arxiv.org/abs/2405.14616)
- [Time-MoE (ICLR 2025)](https://arxiv.org/abs/2409.16040)
- [TimesNet (ICLR 2023)](https://arxiv.org/abs/2210.02186)
- [PatchTST (ICLR 2023)](https://arxiv.org/abs/2211.14730)

### 9.2 ä»£ç åº“

- [Time-Series-Library](https://github.com/thuml/Time-Series-Library) - åŒ…å« iTransformer, TimesNet, PatchTST ç­‰
- [TimeMixer](https://github.com/kwuking/TimeMixer)
- [Time-MoE](https://github.com/Time-MoE/Time-MoE)

---

## åã€æ€»ç»“

æœ¬æ–‡æ¡£æå‡ºäº†äº”ä¸ªåŸºäºæœ€æ–°ç ”ç©¶çš„ Time-LLM æ”¹è¿›æ–¹æ¡ˆ:

1. **å¤šå°ºåº¦åˆ†è§£æ··åˆ**: å€Ÿé‰´ TimeMixerï¼Œæ•è·ä¸åŒå°ºåº¦çš„æ—¶åºæ¨¡å¼
2. **å˜é‡é—´æ³¨æ„åŠ›å¢å¼º**: å€Ÿé‰´ iTransformerï¼Œå»ºæ¨¡å¤šå˜é‡ç›¸å…³æ€§
3. **åŠ¨æ€ Prompt ç”Ÿæˆ**: æå‡å¯¹éå¹³ç¨³æ—¶åºçš„é€‚åº”èƒ½åŠ›
4. **ç¨€ç–ä¸“å®¶æ··åˆ**: å€Ÿé‰´ Time-MoEï¼Œé«˜æ•ˆæ‰©å±•æ¨¡å‹å®¹é‡
5. **é¢‘åŸŸå¢å¼º**: å€Ÿé‰´ TimesNetï¼Œåˆ†ç¦»è¶‹åŠ¿å’Œå­£èŠ‚æ€§æˆåˆ†

**æ¨èå®æ–½è·¯å¾„**:
1. å…ˆå®ç°æ–¹æ¡ˆäºŒ (å˜é‡é—´æ³¨æ„åŠ›) - æ”¹åŠ¨å°ï¼Œæ”¶ç›Šé«˜
2. å†å®ç°æ–¹æ¡ˆäº” (é¢‘åŸŸå¢å¼º) - å¯¹å‘¨æœŸæ€§æ•°æ®æ•ˆæœå¥½
3. æœ€åå°è¯•æ–¹æ¡ˆä¸€ (å¤šå°ºåº¦åˆ†è§£) - å…¨é¢æå‡

---

**æ–‡æ¡£æ›´æ–°æ—¶é—´**: 2026-01-02
**å‚è€ƒæ–‡çŒ®**: ICLR 2023-2025, NeurIPS 2024
**ä½œè€…**: Zhenda Wang

Sources:
- [Time-Series-Library (GitHub)](https://github.com/thuml/Time-Series-Library)
- [TimeMixer (GitHub)](https://github.com/kwuking/TimeMixer)
- [Time-MoE (GitHub)](https://github.com/Time-MoE/Time-MoE)
- [iTransformer Article](https://www.datasciencewithmarco.com/blog/itransformer-the-latest-breakthrough-in-time-series-forecasting)
- [TimeMixer Article](https://medium.com/the-forecaster/timemixer-exploring-the-latest-model-in-time-series-forecasting-056d9c883f46)
